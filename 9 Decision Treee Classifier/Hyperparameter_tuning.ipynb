{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. max_depth:\n",
    "\n",
    "* The first hyperparameter to tune in a Decision tree is max_depth.\n",
    "\n",
    "* It indicates how deep the decision tree can be.\n",
    "\n",
    "* The deeper the tree, the more splits it has & it captures more information about the data.\n",
    "\n",
    "* However, in general a decision tree overfitd for large depth values. The tree perfectly predicts all of the train data, however, it fails to generalize the findings for new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. min_sample_split:\n",
    "\n",
    "* An internal node will have further splits(also called children).\n",
    "\n",
    "* min_samples_split specifies the minimum number of samples required to split an internal node.\n",
    "\n",
    "* We can either specify a number ti denote the minimum number or a fraction to denote the percentage of samples in an internal node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. min_samples_leaf:\n",
    "\n",
    "* A leaf node is a node wthout an children(without any further splits).\n",
    "\n",
    "* min_samples_leaf is the minimum number of samples required to be at a leaf node.\n",
    "\n",
    "* This parameter is similar to min_samples_splits, however, this describe the minimum number of samples at the leafs, the base of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
